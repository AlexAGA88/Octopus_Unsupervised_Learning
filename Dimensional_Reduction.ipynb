{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction on MNIST: PCA & t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!sudo apt-get -y install libopenblas-dev liblapack-dev  # Ideally would put in a Sherlock environment\n",
    "!sudo apt-get -y install libatlas-base-dev\n",
    "!pip install git+https://github.com/alexisbcook/tsne.git\n",
    "# !wget http://deeplearning.net/data/mnist/mnist.pkl.gz\n",
    "!pip install hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import gzip, pickle\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import hdbscan\n",
    "from sklearn.decomposition import PCA\n",
    "from tsne import bh_sne\n",
    "\n",
    "import seaborn as sns\n",
    "palette = np.array(sns.color_palette(\"hls\", 11))\n",
    "\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The famous MNIST dataset is a collection of images of hand-written digits. A classic problem and now benchmmark for models in machine learning is whether it is possible to train a classifier to distinguish between these different digits. The MNIST dataset is actually labelled and so is appropriate for supervised learning but here we'll look at the extent to which purely unsupervised methods are able to segment it. In other words, we will only use the labels to check how well we've done at the end of the calculation. Each digit is represented as a (28x28) array of pixels and the dataset contains 70,000 images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = gzip.open(\"mnist.pkl.gz\", \"rb\")\n",
    "train, val, test = pickle.load(f, encoding='latin1')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.asarray(np.vstack((train[0], val[0], test[0])), dtype=np.float64)\n",
    "y = np.hstack((train[1], val[1], test[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_cols = ['pixel'+ str(i) for i in range(X.shape[1])]\n",
    "df = pd.DataFrame(X,columns=feat_cols)\n",
    "df['label'] = y.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is instructive to view the first few of these MNIST digits. The function below plots the first thirty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize=(16,7) )\n",
    "for i in range(0,30):\n",
    "    ax = fig.add_subplot(3,10,i+1)\n",
    "    ax.matshow(df.loc[i,feat_cols].values.reshape((28,28)).astype(float))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(df.loc[:, feat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.scatter(pca_result[:,0], pca_result[:,1])\n",
    "ax2.scatter(pca_result[:,0], pca_result[:,1], c=palette[df['label'].astype(np.int)])\n",
    "ax1.set_xlabel('PCA1')\n",
    "ax1.set_ylabel('PCA2')\n",
    "ax2.set_xlabel('PCA1')\n",
    "ax2.set_ylabel('PCA2')\n",
    "ax2.set_title('Coloured by the True Labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. K-means clustering of PCA results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = KMeans(n_clusters = 10, init='k-means++', random_state = 42)\n",
    "clf.fit(pca_result)\n",
    "indices= clf.labels_\n",
    "df['pca label'] = indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(16, 16))\n",
    "ax = plt.subplot(aspect='equal')\n",
    "sc = ax.scatter( pca_result[:,0], pca_result[:,1], c=palette[indices.astype(np.int)] )\n",
    "ax.set_xlabel('PCA1')\n",
    "ax.set_ylabel('PCA2')\n",
    "ax.set_title('Coloured by K-means labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now group the dataframe by cluster label. We will attempt to eyeball features within each cluster in order to assign a true digit label to each cluster. We can do this by plotting a sample of images from each clusters and looking at what digits actually appear (remember the pixel values are the features and we are allowed to use these - just not the true labels). You can experiment with this, varying cluster_number from 0-9 and trying to assign a label to each of the 10 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_clusters = {k: v for k, v in df.groupby('pca label')}\n",
    "\n",
    "cluster_number = 6\n",
    "fig = plt.figure( figsize=(16,7) )\n",
    "for i in range(0,50):\n",
    "    ax = fig.add_subplot(5,10,i+1)\n",
    "    cluster_frames = dict_of_clusters[cluster_number].loc[:, feat_cols]\n",
    "    ax.matshow(cluster_frames.iloc[i].values.reshape((28,28)).astype(float))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Eyeballed dictionary between cluster labels and the true labels  - have a go at this\n",
    "true_labels_map = {0:3, 1:4, 2:6, 3:1, 4:2, 5:0, 6:5, 7:9, 8:8, 9:7} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['pca predicted'] = df.loc[:, 'pca label'].apply(lambda x: true_labels_map[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df['label']==df['pca predicted'])\n",
    "accuracy = (df.loc[mask].shape[0])/(df.shape[0])\n",
    "print(\"Percentage Accuracy of PCA + kmeans unsupervised learning = ~\", 100*accuracy) # You'll get about 35% for PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. t-Distributed Stochastic Neighbour Embedding (t-SNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since t-SNE can be quite slow to run, we load the results from a .csv file. The code to run the algorithm is shown below (commented). The first implementation is the one found at https://github.com/alexisbcook/tsne, whilst the latter is the sklearn implementation. Note that the former seems to be faster and also more able to handle large datasets than the sklearn implementation, however it does not have a functional random_state parameter so save your output (it will not be exactly reproducible as t-SNE is not deterministic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tsne_result = np.genfromtxt ('MNIST_large_tsne.csv', delimiter=\",\") # Generated from the bh_sne() code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implementation from https://github.com/alexisbcook/tsne - takes of the order 20 minutes to run\n",
    "# time_start = time.time()\n",
    "# tsne_result = bh_sne(df.loc[:, feat_cols])\n",
    "# print(  't-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implementation from sklearn - this implementation may crash on the full MNIST data (may need a subset)\n",
    "# time_start = time.time()\n",
    "# tsne = TSNE(n_components=2, verbose=1, perplexity=50, n_iter=300, random_state = 42) \n",
    "# tsne_result = tsne.fit_transform(df_sample.loc[:, feat_cols]) \n",
    "# print(  't-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.scatter(tsne_result[:,0], tsne_result[:,1])\n",
    "ax2.scatter(tsne_result[:,0], tsne_result[:,1], c=palette[df['label'].astype(np.int)])\n",
    "ax1.set_xlabel('tSNE1')\n",
    "ax1.set_ylabel('tSNE2')\n",
    "ax2.set_xlabel('tSNE1')\n",
    "ax2.set_ylabel('tSNE2')\n",
    "ax2.set_title('Coloured by the True Labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = KMeans(n_clusters = 10, init='k-means++', random_state = 42)\n",
    "clf.fit(tsne_result)\n",
    "indices= clf.labels_\n",
    "df['tsne label'] = indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot these results\n",
    "f = plt.figure(figsize=(16, 16))\n",
    "ax = plt.subplot(aspect='equal')\n",
    "sc = ax.scatter( tsne_result[:,0], tsne_result[:,1], c=palette[indices.astype(np.int)] )\n",
    "ax.set_xlabel('tSNE1')\n",
    "ax.set_ylabel('tSNE2')\n",
    "ax.set_title('Coloured by K-means labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_clusters = {k: v for k, v in df.groupby('tsne label')}\n",
    "\n",
    "cluster_number = 8\n",
    "fig = plt.figure( figsize=(16,7) )\n",
    "for i in range(0,50):\n",
    "    ax = fig.add_subplot(5,10,i+1)\n",
    "    cluster_frames = dict_of_clusters[cluster_number].loc[:, feat_cols]\n",
    "    ax.matshow(cluster_frames.iloc[i].values.reshape((28,28)).astype(float))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_labels_map = {0:6, 1:3, 2:1, 3:0, 4:4, 5:8, 6:2, 7:7, 8:5, 9:9}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['tsne predicted'] = df.loc[:, 'tsne label'].apply(lambda x: true_labels_map[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df['label']==df['tsne predicted'])\n",
    "accuracy = (df.loc[mask].shape[0])/(df.shape[0])\n",
    "print(\"Percentage Accuracy of tSNE + kmeans unsupervised learning = ~\", 100*accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Pushing the Accuracy Higher: Hierarchical DBSCAN (HDBSCAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = hdbscan.HDBSCAN(min_cluster_size=56)\n",
    "clf.fit(tsne_result)\n",
    "indices_hdbcsan = clf.labels_\n",
    "df['HDBSCAN label'] = indices_hdbcsan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(indices_hdbcsan)) # DBSCAN + HDBSCAN includes 'not assigned to any cluster' as an option - hence the 11 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(16, 16))\n",
    "ax = plt.subplot(aspect='equal')\n",
    "sc = ax.scatter( tsne_result[:,0], tsne_result[:,1], c=palette[indices_hdbcsan.astype(np.int)] )\n",
    "ax.set_xlabel('tSNE1')\n",
    "ax.set_ylabel('tSNE2')\n",
    "ax.set_title('Coloured by HDBSCAN labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop points that do not belong to any cluster\n",
    "mask = (df['HDBSCAN label'] != -1)\n",
    "df_signal = df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_clusters = {k: v for k, v in df_signal.groupby('HDBSCAN label')}\n",
    "\n",
    "cluster_number = 7\n",
    "fig = plt.figure( figsize=(16,7) )\n",
    "for i in range(0,50):\n",
    "    ax = fig.add_subplot(5,10,i+1)\n",
    "    cluster_frames = dict_of_clusters[cluster_number].loc[:, feat_cols]\n",
    "    ax.matshow(cluster_frames.iloc[i].values.reshape((28,28)).astype(float))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_labels_map = {0:0, 1:6, 2:7, 3:9, 4:5, 5:3, 6:1, 7:8, 8:4, 9:2}  # Cluster 3 contains (9,4) - can separate them by \n",
    "                                                                      # further perplexity tuning in tSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_signal['tsne HDBSCAN predicted'] = df_signal.loc[:, 'HDBSCAN label'].apply(lambda x: true_labels_map[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df_signal['label']==df_signal['tsne HDBSCAN predicted'])\n",
    "accuracy = (df_signal.loc[mask].shape[0])/(df_signal.shape[0])\n",
    "print(\"Percentage Accuracy of tSNE + HDBSCAN unsupervised learning = ~\", 100*accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3]",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
